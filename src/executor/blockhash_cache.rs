use std::sync::{Arc, RwLock, atomic::{AtomicBool, Ordering}};
use std::time::{Duration, Instant};
use solana_sdk::hash::Hash;
use solana_client::rpc_client::RpcClient;
use tokio::time::sleep;
use log::{info, warn, error, debug};

use crate::executor::errors::ExecutionError;

/// åŒºå—å“ˆå¸Œç¼“å­˜ï¼Œç”¨äºåå°è·å–æœ€æ–°åŒºå—å“ˆå¸Œå’Œsloté«˜åº¦
pub struct BlockhashCache {
    /// ç¼“å­˜çš„åŒºå—å“ˆå¸Œã€sloté«˜åº¦å’Œè·å–æ—¶é—´
    cached_data: Arc<RwLock<Option<(Hash, u64, Instant)>>>,
    /// RPCå®¢æˆ·ç«¯
    rpc_client: RpcClient,
    /// è¿è¡ŒçŠ¶æ€æ ‡å¿—
    running: Arc<AtomicBool>,
    /// åå°ä»»åŠ¡å¥æŸ„
    task_handle: Option<tokio::task::JoinHandle<()>>,
}

impl BlockhashCache {
    /// åˆ›å»ºæ–°çš„åŒºå—å“ˆå¸Œç¼“å­˜
    /// rpc_endpoint_with_auth: åŒ…å«è®¤è¯ä¿¡æ¯çš„å®Œæ•´RPCç«¯ç‚¹URL
    pub fn new(rpc_endpoint_with_auth: String) -> Self {
        let rpc_client = RpcClient::new(rpc_endpoint_with_auth);
        
        Self {
            cached_data: Arc::new(RwLock::new(None)),
            rpc_client,
            running: Arc::new(AtomicBool::new(false)),
            task_handle: None,
        }
    }

    /// å¯åŠ¨åå°æ›´æ–°ä»»åŠ¡
    pub fn start(&mut self) -> Result<(), ExecutionError> {
        if self.running.load(Ordering::Relaxed) {
            warn!("BlockhashCache already running");
            return Ok(());
        }

        self.running.store(true, Ordering::Relaxed);
        
        let cached_data = Arc::clone(&self.cached_data);
        let rpc_endpoint = self.rpc_client.url();
        let running = Arc::clone(&self.running);

        let handle = tokio::spawn(async move {
            info!("ğŸš€ BlockhashCache background task started");
            
            // åœ¨å¼‚æ­¥ä»»åŠ¡ä¸­åˆ›å»ºRPCå®¢æˆ·ç«¯
            let rpc_client = RpcClient::new(rpc_endpoint);
            
            while running.load(Ordering::Relaxed) {
                match Self::fetch_latest_data(&rpc_client).await {
                    Ok((blockhash, slot)) => {
                        let now = Instant::now();
                        
                        // æ›´æ–°ç¼“å­˜
                        if let Ok(mut cache) = cached_data.write() {
                            *cache = Some((blockhash, slot, now));
                            debug!("âœ… Updated cached data: blockhash={}, slot={}", blockhash, slot);
                        } else {
                            warn!("âš ï¸ Failed to acquire write lock for cache");
                        }
                    }   
                    Err(e) => {
                        error!("âŒ Failed to fetch latest blockhash and slot: {}", e);
                        // è·å–å¤±è´¥æ—¶ä¸æ›´æ–°ç¼“å­˜ï¼Œç»§ç»­ä½¿ç”¨æ—§çš„ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    }
                }

                // ç­‰å¾…100msåå†æ¬¡å°è¯•
                sleep(Duration::from_millis(100)).await;
            }
            
            info!("ğŸ›‘ BlockhashCache background task stopped");
        });

        self.task_handle = Some(handle);
        Ok(())
    }

    /// åœæ­¢åå°æ›´æ–°ä»»åŠ¡
    pub async fn stop(&mut self) {
        self.running.store(false, Ordering::Relaxed);
        
        if let Some(handle) = self.task_handle.take() {
            if let Err(e) = handle.await {
                error!("Failed to stop blockhash cache task: {}", e);
            }
        }
        
        info!("BlockhashCache stopped");
    }

    /// è·å–ç¼“å­˜çš„åŒºå—å“ˆå¸Œ
    pub fn get_cached_blockhash(&self) -> Result<Hash, ExecutionError> {
        let cache = self.cached_data.read()
            .map_err(|_| ExecutionError::Configuration("Failed to read cache".to_string()))?;

        match cache.as_ref() {
            Some((blockhash, _slot, timestamp)) => {
                // æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆè¶…è¿‡10ç§’ï¼‰
                if timestamp.elapsed().as_secs() > 10 {
                    warn!("âš ï¸ Cached blockhash is stale ({:.1}s old), but using it anyway", 
                          timestamp.elapsed().as_secs_f64());
                }
                Ok(*blockhash)
            }
            None => {
                // å¦‚æœç¼“å­˜ä¸ºç©ºï¼Œå°è¯•åŒæ­¥è·å–ä¸€æ¬¡
                warn!("ğŸ“‹ Cache empty, attempting sync fetch");
                Err(ExecutionError::ServiceUnavailable {
                    service: "BlockhashCache".to_string(),
                    reason: "No cached blockhash available".to_string(),
                })
            }
        }
    }

    /// å¼ºåˆ¶åŒæ­¥è·å–æœ€æ–°åŒºå—å“ˆå¸Œï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    pub async fn get_fresh_blockhash(&self) -> Result<Hash, ExecutionError> {
        let (blockhash, _slot) = Self::fetch_latest_data(&self.rpc_client).await?;
        Ok(blockhash)
    }

    /// è·å–ç¼“å­˜çŠ¶æ€ä¿¡æ¯
    pub fn get_cache_info(&self) -> Result<CacheInfo, ExecutionError> {
        let cache = self.cached_data.read()
            .map_err(|_| ExecutionError::Configuration("Failed to read cache".to_string()))?;

        let info = match cache.as_ref() {
            Some((blockhash, slot, timestamp)) => CacheInfo {
                has_cache: true,
                blockhash: Some(*blockhash),
                slot: Some(*slot),
                age_seconds: timestamp.elapsed().as_secs_f64(),
                is_stale: timestamp.elapsed().as_secs() > 10,
            },
            None => CacheInfo {
                has_cache: false,
                blockhash: None,
                slot: None,
                age_seconds: 0.0,
                is_stale: true,
            },
        };

        Ok(info)
    }

    /// å†…éƒ¨æ–¹æ³•ï¼šè·å–æœ€æ–°åŒºå—å“ˆå¸Œå’Œslot
    async fn fetch_latest_data(rpc_client: &RpcClient) -> Result<(Hash, u64), ExecutionError> {
        // å¹¶å‘è·å–blockhashå’Œslotä»¥æé«˜æ•ˆç‡
        let (blockhash_result, slot_result) = tokio::join!(
            async { rpc_client.get_latest_blockhash() },
            async { rpc_client.get_slot() }
        );

        let blockhash = blockhash_result
            .map_err(|e| ExecutionError::Network(format!("Failed to fetch latest blockhash: {}", e)))?;
        let slot = slot_result
            .map_err(|e| ExecutionError::Network(format!("Failed to fetch current slot: {}", e)))?;

        Ok((blockhash, slot))
    }

    /// æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ
    pub fn is_running(&self) -> bool {
        self.running.load(Ordering::Relaxed)
    }

    /// è·å–å½“å‰sloté«˜åº¦ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼‰
    pub async fn get_current_slot(&self) -> Result<u64, ExecutionError> {
        // ä¼˜å…ˆä»ç¼“å­˜è·å–
        if let Ok(cache) = self.cached_data.read() {
            if let Some((_blockhash, slot, timestamp)) = cache.as_ref() {
                // å¦‚æœç¼“å­˜æœªè¿‡æœŸï¼ˆå°äº10ç§’ï¼‰ï¼Œç›´æ¥è¿”å›ç¼“å­˜çš„slot
                if timestamp.elapsed().as_secs() <= 10 {
                    return Ok(*slot);
                }
            }
        }

        // ç¼“å­˜è¿‡æœŸæˆ–ä¸å­˜åœ¨æ—¶ï¼Œå®æ—¶è·å–
        warn!("ğŸ”„ Cache stale or empty, fetching fresh slot");
        self.rpc_client.get_slot()
            .map_err(|e| ExecutionError::Network(format!("Failed to fetch current slot: {}", e)))
    }

    /// è·å–ç¼“å­˜çš„sloté«˜åº¦ï¼ˆä¸è¿›è¡Œå®æ—¶æŸ¥è¯¢ï¼‰
    pub fn get_cached_slot(&self) -> Result<u64, ExecutionError> {
        let cache = self.cached_data.read()
            .map_err(|_| ExecutionError::Configuration("Failed to read cache".to_string()))?;

        match cache.as_ref() {
            Some((_blockhash, slot, timestamp)) => {
                // æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆè¶…è¿‡10ç§’ï¼‰
                if timestamp.elapsed().as_secs() > 10 {
                    warn!("âš ï¸ Cached slot is stale ({:.1}s old), but using it anyway", 
                          timestamp.elapsed().as_secs_f64());
                }
                Ok(*slot)
            }
            None => {
                Err(ExecutionError::ServiceUnavailable {
                    service: "BlockhashCache".to_string(),
                    reason: "No cached slot available".to_string(),
                })
            }
        }
    }
}

impl Drop for BlockhashCache {
    fn drop(&mut self) {
        self.running.store(false, Ordering::Relaxed);
    }
}

/// ç¼“å­˜çŠ¶æ€ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct CacheInfo {
    pub has_cache: bool,
    pub blockhash: Option<Hash>,
    pub slot: Option<u64>,
    pub age_seconds: f64,
    pub is_stale: bool,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_cache_creation() {
        let cache = BlockhashCache::new("https://api.mainnet-beta.solana.com".to_string());
        assert!(!cache.is_running());
        
        let info = cache.get_cache_info().unwrap();
        assert!(!info.has_cache);
        assert!(info.is_stale);
    }

    #[tokio::test]
    async fn test_cache_start_stop() {
        let mut cache = BlockhashCache::new("https://api.mainnet-beta.solana.com".to_string());
        
        // å¯åŠ¨
        cache.start().unwrap();
        assert!(cache.is_running());
        
        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©åå°ä»»åŠ¡è¿è¡Œ
        tokio::time::sleep(Duration::from_millis(200)).await;
        
        // åœæ­¢
        cache.stop().await;
        assert!(!cache.is_running());
    }
}